{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e909caf5-2d9b-42c1-8da5-90da97c22ce4",
   "metadata": {},
   "source": [
    "<center><img src='fig/YOLO-v3-network.jpg'><center>\n",
    "<center><img src='fig/YOLOv3_layers.png'><center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038b155d-8cab-4c42-bc0a-575d0769d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of YOLOv3 architecture\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\"\"\" \n",
    "Information about architecture config:\n",
    "Tuple is structured by (filters, kernel_size, stride) \n",
    "Every conv is a same convolution. \n",
    "List is structured by \"B\" indicating a residual block followed by the number of repeats\n",
    "\"S\" is for scale prediction block and computing the yolo loss\n",
    "\"U\" is for upsampling the feature map and concatenating with a previous layer\n",
    "\"\"\"\n",
    "# Tuple: (out_channels, kernel_size, stride)\n",
    "# List: [\"B\", num_of_repeats]\n",
    "# residual blocks use the last two tuples\n",
    "config = [\n",
    "    (32, 3, 1),\n",
    "    (64, 3, 2),\n",
    "    [\"B\", 1],\n",
    "    (128, 3, 2),\n",
    "    [\"B\", 2],\n",
    "    (256, 3, 2),\n",
    "    [\"B\", 8],\n",
    "    (512, 3, 2),\n",
    "    [\"B\", 8],\n",
    "    (1024, 3, 2),\n",
    "    [\"B\", 4],  # To this point is Darknet-53\n",
    "    (512, 1, 1),\n",
    "    (1024, 3, 1),\n",
    "    \"S\", # scaled prediction 1\n",
    "    (256, 1, 1),\n",
    "    \"U\", # upsampling\n",
    "    (256, 1, 1),\n",
    "    (512, 3, 1),\n",
    "    \"S\", # scaled prediction 2\n",
    "    (128, 1, 1),\n",
    "    \"U\", # upsampling\n",
    "    (128, 1, 1),\n",
    "    (256, 3, 1),\n",
    "    \"S\", # scaled prediction 3\n",
    "]\n",
    "\n",
    "# CNN block\n",
    "class CNNBlock(nn.module):\n",
    "    # bn_act is used to define if the block is going to be using batch norm activation function\n",
    "    def __init__(self, in_channels, out_channels, bn_act = True, **kwargs):\n",
    "        super().__init__()\n",
    "        # if you used batch normalization, then bias is an unneccessary paramenter, thus the not bn_act\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias = not bn_act, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.leaky = nn.LeakyReLU(0.1) # activation function\n",
    "        self.use_bn_act = bn_act\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # this if is here because on scaled predictions we aren't going to use batch norm activation\n",
    "        # scaled predictions are going to be outputs, so we don't want to bn those.\n",
    "        if self.use_bn_act:\n",
    "            return self.leaky(self.bn(self.conv(x)))\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    # the reason why use_residual is specified is because in some cases we will use skip connection,\n",
    "    # while in others it'll just go through the config file and not use it\n",
    "    # default of num_repeats is 1, but the actual value used will depend of the num_repeat argument\n",
    "    # in the lists [\"B\", num_repeats]\n",
    "    def __init__(self, channels, use_residual = True, num_repeats=1):\n",
    "        super().__init__()\n",
    "        self.layers() = nn.ModuleList()\n",
    "        for repeat in num_repeats:\n",
    "            # this reduces the number of filters, then brings it back again\n",
    "            self.layers += [nn.Sequential(CNNBlock(channels, channels//2, kernel_size = 1),\n",
    "                                          CNNBlock(channels//2, channels, kernel_size = 3, padding = 1),\n",
    "                                         )\n",
    "                           ]\n",
    "        self.use_residual = use_residual\n",
    "        self.num_repeats = num_repeats\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # we didn't change anything, same padding and same number of channels.\n",
    "        # so we arejust adding x after it go through the conv layers.\n",
    "        # however, if we aren't using residual, just layer of x\n",
    "        for layer in self.layers:\n",
    "            x = layer(x) + x if self.use_residual else layer(x)\n",
    "        return x\n",
    "                \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "class ScalePrediction(nn.Module):\n",
    "    pass\n",
    "\n",
    "class YOLOv3(nn.Module):\n",
    "    pass\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
